import os
import numpy as np
from numpy import clip
import random
import scipy.misc
from sklearn.model_selection import train_test_split, StratifiedKFold, KFold
from itertools import groupby
from PIL import Image
from scipy.misc import toimage
from keras.applications.vgg16 import preprocess_input

import matplotlib.pyplot as plt



def get_class_index(data_dir):
    class_index = dict()
    label = np.load(os.path.join(data_dir,'label.npy'), allow_pickle=True)
    num = 1
    for i in sorted(list(set(label))):
        class_index[i] = num
        num += 1
    return class_index

def get_seqLen(data_path):
    '''
    Get the number of subframes for each videos, choose the minimun length amoung all of them
    :param data: List of videos in tuple [((6,200,200,3),label), ...]
    :return
    '''
    data = np.load(data_path,allow_pickle=True)
#     import collections
#     print (collections.Counter([v[0].shape[0] for v in data]))    # get the statistic of the length list
    seqLen_list = [v[0].shape[0] for v in data]
    return min(seqLen_list)


def get_norm_frame(frame, normalization=True, mean=None):
    frame = frame.astype('float64')
    if mean is not None:
        frame -= mean
    if normalization == True:
        frame *= 1/255
    frame = clip(frame, -1.0, 1.0)
    # shift from [-1,1] to [0,1] with 0.5 mean
    frame = (frame + 1.0) / 2.0

    return frame
        

def get_data_list(processed_dir,frame_dir, SEQ_LEN, class_index,mean):
    # get list of file name, a list of label number
    X = []
    Y = []
    # print ('UCF_utils - line 60 - ', class_index)
    data = np.load(os.path.join(processed_dir,'data_videoName.npy'),allow_pickle=True)
    print ('Start preprocess data.... ')
    for t in data:
        video = t[0][:SEQ_LEN]   # (seq_len, 200, 200, 3)
        # normalize the video frame from 0-255 to 0-1
        video_norm = get_norm_frame(video,mean=mean, normalization=True)
        videoname = t[1]
        label = '_'.join(videoname.split('_')[:-2])
        label_num = class_index.get(label)
        if not os.path.isdir(os.path.join(frame_dir,label)):
            os.makedirs(os.path.join(frame_dir,label))
        np.save(os.path.join(frame_dir,label,videoname+'.npy'), video_norm)
        X.append(os.path.join(frame_dir,label,videoname+'.npy'))
        Y.append(label_num)
    # random shuffle the data and label
    idx = np.random.permutation(len(X))
    x,y = np.array(X)[idx], np.array(Y)[idx]
    print ('Data processed and saved in %s'%frame_dir)
    return x,y


def get_train_test(data, label, processed_dir, class_index, cnn_predict=False):
    # split train test and save the npy in train and test folder
    trainX, testX, trainY, testY = train_test_split(data, label, stratify=label, random_state=0)  
    trainlist = []
    testlist = []
    if cnn_predict == True:
        print ('Start splitting train and test for CNN training...')
        train_dir = os.path.join(processed_dir,'train')
        test_dir = os.path.join(processed_dir,'test')
    else:
        print ('Start splitting train and test for CNN feature extraction...')
        train_dir = os.path.join(processed_dir, 'CNN_Predicted', 'train')
        test_dir = os.path.join(processed_dir, 'CNN_Predicted', 'test')
    if not os.path.isdir(train_dir):
        os.makedirs(train_dir)
    if not os.path.isdir(test_dir):
        os.makedirs(test_dir)
    for i, j in zip(trainX, trainY):
        current_label = list(class_index.keys())[list(class_index.values()).index(j)]
        if cnn_predict == True:
            if not os.path.isdir(os.path.join(train_dir,current_label)):
                os.makedirs(os.path.join(train_dir,current_label))
            np.save(os.path.join(train_dir,current_label, i.split('/')[-1]), np.load(i,allow_pickle=True))
            trainlist.append((i,j))
        else:
            trainlist.append((os.path.join(train_dir,current_label, i.split('/')[-1]),j))
    for i, j in zip (testX, testY):
        current_label = list(class_index.keys())[list(class_index.values()).index(j)]
        if cnn_predict == True:
            if not os.path.isdir(os.path.join(test_dir,current_label)):
                os.makedirs(os.path.join(test_dir,current_label))
            np.save(os.path.join(test_dir,current_label, i.split('/')[-1]), np.load(i,allow_pickle=True))
            testlist.append((i,j))
        else:
            testlist.append((os.path.join(test_dir,current_label, i.split('/')[-1]),j))
    
    print ('Split done.')

    return trainlist, testlist


def sequence_generator(data_list, batch_size, input_shape, num_classes):
    '''
    Read sequence data of batch_size into memory
    :param data_list: The data generated by get_data_list, a list of tuple [('data_path', label_num), ...]
    :param batch_size:
    :param input_shape: tuple: the shape of numpy ndarray
    :param num_classes:
    :return:
    '''
    if isinstance(input_shape, tuple):
        x_shape = (batch_size,) + input_shape
    else:
        raise ValueError('Input shape is neither 1D or 3D')
    y_shape = (batch_size, num_classes)
    index = 0
    while True:
        batch_x = np.ndarray(x_shape)
        batch_y = np.zeros(y_shape)
        for i in range(batch_size):
            step = random.randint(1, len(data_list) - 1)  # approach a random-size step to get the next video sample
            index = (index + step) % len(data_list)
            clip_dir, clip_class = data_list[index])
            batch_y[i, clip_class - 1] = 1
            # avoid endless loop
            count = 0
            while not os.path.exists(clip_dir):
                count += 1
                if count > 20:
                    raise FileExistsError('Too many file missing')
                index = (index + 1) % len(data_list)
                clip_dir, class_idx = data_list[index]

            clip_data = np.load(clip_dir)   
            if clip_data.shape != batch_x.shape[1:]:
                raise ValueError('The number of time sequence is inconsistent with the video data')
            batch_x[i] = clip_data
            # print (batch_x.shape, batch_y.shape)

        yield batch_x, batch_y


def image_from_sequence_generator(data_list, batch_size, input_shape, num_classes):
    '''
        Read one frame in the sequence data into memory
        input_shape: (seq_len,) + img_size
    '''
    batch_image_shape = (batch_size,) + input_shape[1:]
    batch_image = np.ndarray(batch_image_shape)   # 4-D

    video_gen = sequence_generator(data_list, batch_size, input_shape, num_classes)

    while True:
        batch_video, batch_label = next(video_gen)    # 5_D
        for idx, video in enumerate(batch_video):     
            sample_frame_idx = random.randint(0, input_shape[0] - 1) 
            sample_frame = video[sample_frame_idx]
            batch_image[idx] = sample_frame
       
        yield batch_image, batch_label


